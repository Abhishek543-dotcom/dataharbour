services:
  # Backend API service
  backend:
    build: ./backend
    ports:
      - "8000:8000"  # FastAPI backend
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
      - ./data/notebooks:/data/notebooks
    environment:
      - DATABASE_URL=postgresql://admin:admin@postgres:5432/dataharbour
      - JWT_SECRET_KEY=09d25e094faa6ca2556c818166b7a9563b93f7099f6f0f4caa6cf63b88e8d3e7
      - JWT_ALGORITHM=HS256
      - ACCESS_TOKEN_EXPIRE_MINUTES=30
      - ENABLE_AUTH=true
      - ENABLE_REGISTRATION=true
      - SPARK_MASTER_URL=spark://spark:7077
      - SPARK_UI_URL=http://spark:4040
      - AIRFLOW_BASE_URL=http://airflow-webserver:8080
      - AIRFLOW_USERNAME=admin
      - AIRFLOW_PASSWORD=admin
      - JUPYTER_BASE_URL=http://jupyter:8888
      - POSTGRES_HOST=postgres
      - POSTGRES_PORT=5432
      - POSTGRES_USER=admin
      - POSTGRES_PASSWORD=admin
      - POSTGRES_DB=dataharbour
      - MINIO_ENDPOINT=minio:9000
      - MINIO_ACCESS_KEY=minioadmin
      - MINIO_SECRET_KEY=minioadmin
      - MINIO_SECURE=false
      - MINIO_BUCKET_NAME=dataharbour
      - ENVIRONMENT=development
    depends_on:
      - spark
      - jupyter
      - postgres
      - minio
      - airflow-webserver
    networks:
      - dataharbour-network

  # React Frontend (Production build)
  frontend:
    build: ./frontend
    ports:
      - "3000:80"
    depends_on:
      - backend
    networks:
      - dataharbour-network

  # Spark service - using Jupyter PySpark notebook which includes Spark
  spark:
    image: jupyter/pyspark-notebook:latest
    ports:
      - "4040:4040"  # Spark UI port
      - "7077:7077"  # Spark Master port
      - "8080:8080"  # Spark Master Web UI
      - "8889:8888"  # Jupyter port (different from main jupyter service)
    environment:
      - JUPYTER_ENABLE_LAB=yes
    command: start.sh spark-master
    volumes:
      - ./data/spark:/home/jovyan/work
    depends_on:
      - postgres
      - minio
    networks:
      - dataharbour-network

  # Jupyter Notebook service
  jupyter:
    image: jupyter/base-notebook:latest
    ports:
      - "8888:8888"  # Jupyter Notebook interface
    volumes:
      - ./data/jupyter:/home/jovyan/work
    networks:
      - dataharbour-network
    #environment:
    #  - JUPYTER_TOKEN= "qwertyuiopasdffghjkl"  # Replace with your desired token

  # PostgreSQL database service
  postgres:
    image: postgres:13
    ports:
      - "5432:5432"
    environment:
      - POSTGRES_USER=admin
      - POSTGRES_PASSWORD=admin
      - POSTGRES_DB=dataharbour
      - PGDATA=/var/lib/postgresql/data/pgdata
    volumes:
      - postgres-data:/var/lib/postgresql/data
      - ./scripts/init-db.sh:/docker-entrypoint-initdb.d/init-db.sh
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U admin -d dataharbour"]
      interval: 5s
      timeout: 5s
      retries: 5
    networks:
      - dataharbour-network

  # pgAdmin service for PostgreSQL management
  pgadmin:
    image: dpage/pgadmin4
    ports:
      - "5050:80"  # pgAdmin web interface
    environment:
      - PGADMIN_DEFAULT_EMAIL=admin@example.com
      - PGADMIN_DEFAULT_PASSWORD=admin
    depends_on:
      - postgres
    networks:
      - dataharbour-network

  # MinIO service for object storage
  minio:
    image: minio/minio
    ports:
      - "9000:9000"  # MinIO API
      - "9001:9001"  # MinIO Console
    volumes:
      - minio-data:/data
    environment:
      - MINIO_ROOT_USER=minioadmin
      - MINIO_ROOT_PASSWORD=minioadmin
    command: server /data --console-address ":9001"
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9000/minio/health/live"]
      interval: 30s
      timeout: 20s
      retries: 3
    networks:
      - dataharbour-network

  # Airflow scheduler service
  airflow-scheduler:
    image: apache/airflow:2.5.0
    environment:
      - AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=postgresql+psycopg2://admin:admin@postgres:5432/airflow
      - AIRFLOW__CORE__EXECUTOR=LocalExecutor
      - AIRFLOW__CORE__LOAD_EXAMPLES=False
      - AIRFLOW__API__AUTH_BACKENDS=airflow.api.auth.backend.basic_auth
    volumes:
      - ./data/airflow/dags:/opt/airflow/dags
    depends_on:
      postgres:
        condition: service_healthy
    command: scheduler
    networks:
      - dataharbour-network

  # Airflow webserver service
  airflow-webserver:
    image: apache/airflow:2.5.0
    ports:
      - "8081:8080"  # Airflow web interface
    environment:
      - AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=postgresql+psycopg2://admin:admin@postgres:5432/airflow
      - AIRFLOW__CORE__EXECUTOR=LocalExecutor
      - AIRFLOW__CORE__LOAD_EXAMPLES=False
      - AIRFLOW__API__AUTH_BACKENDS=airflow.api.auth.backend.basic_auth
    volumes:
      - ./data/airflow/dags:/opt/airflow/dags
    depends_on:
      postgres:
        condition: service_healthy
    command: webserver
    networks:
      - dataharbour-network

networks:
  dataharbour-network:
    driver: bridge

volumes:
  postgres-data:
  minio-data:
  airflow-data:
  notebook-data:
